{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro-title",
      "metadata": {},
      "source": [
        "# üìò Agentic Architectures 3: ReAct (Reason + Act)\n",
        "\n",
        "Welcome to the third notebook in our series. We will now explore **ReAct**, a pivotal architecture that bridges the gap between simple tool use and complex, multi-step problem-solving. ReAct stands for **Reason + Act**, and its core innovation is the way it enables an agent to dynamically reason about a problem, act on its reasoning, observe the outcome, and then reason again.\n",
        "\n",
        "This pattern transforms an agent from a static tool-caller into an adaptive problem-solver. To highlight its power, we will first build a **basic, single-shot tool-using agent** and show its limitations on a complex task. Then, we will build a full ReAct agent and demonstrate how its iterative `think -> act -> observe` loop allows it to succeed where the basic agent fails."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro-definition",
      "metadata": {},
      "source": [
        "### Definition\n",
        "The **ReAct** architecture is a design pattern where an agent interleaves reasoning steps with actions. Instead of planning all its steps upfront, the agent generates a thought about its immediate next step, takes an action (like calling a tool), observes the result, and then uses that new information to generate its next thought and action. This creates a dynamic and adaptive loop.\n",
        "\n",
        "### High-level Workflow\n",
        "\n",
        "1.  **Receive Goal:** The agent is given a complex task.\n",
        "2.  **Think (Reason):** The agent generates an internal thought, such as: *\"To answer this, I first need to find piece of information X.\"*\n",
        "3.  **Act:** Based on its thought, the agent executes an action, typically calling a tool (e.g., `search_api('X')`).\n",
        "4.  **Observe:** The agent receives the result from the tool.\n",
        "5.  **Repeat:** The agent incorporates the observation into its context and returns to step 2, generating a new thought (e.g., *\"Okay, now that I have X, I need to use it to find Y.\"*). This loop continues until the overall goal is satisfied.\n",
        "\n",
        "### When to Use / Applications\n",
        "*   **Multi-hop Question Answering:** When answering a question requires finding several pieces of information in sequence (e.g., \"Who is the CEO of the company that makes the iPhone?\").\n",
        "*   **Web Navigation & Research:** An agent can search for a starting point, read the results, and then decide on a new search query based on what it learned.\n",
        "*   **Interactive Workflows:** Any task where the environment is dynamic and the full path to a solution cannot be known in advance.\n",
        "\n",
        "### Strengths & Weaknesses\n",
        "*   **Strengths:**\n",
        "    *   **Adaptive & Dynamic:** Can adjust its plan on the fly based on new information.\n",
        "    *   **Handles Complexity:** Excels at problems that require chaining multiple dependent steps.\n",
        "*   **Weaknesses:**\n",
        "    *   **Higher Latency & Cost:** Involves multiple sequential LLM calls, making it slower and more expensive than single-shot approaches.\n",
        "    *   **Risk of Loops:** A poorly guided agent can get stuck in repetitive, unproductive loops of thought and action."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase0-title",
      "metadata": {},
      "source": [
        "## Phase 0: Foundation & Setup\n",
        "\n",
        "We'll begin with our standard setup process: installing libraries and configuring API keys for Together, LangSmith, and our Tavily web search tool."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-what",
      "metadata": {},
      "source": [
        "### Step 0.1: Installing Core Libraries\n",
        "\n",
        "**What we are going to do:**\n",
        "We will install our standard suite of libraries for this project series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install-libs",
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install -q -U langchain-together langchain-tavily langchain langgraph rich python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "imports-what",
      "metadata": {},
      "source": [
        "### Step 0.2: Importing Libraries and Setting Up Keys\n",
        "\n",
        "**What we are going to do:**\n",
        "We will import the necessary modules and load our API keys from a `.env` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "import-and-keys",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables loaded and tracing is set up.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import Annotated\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# LangChain components\n",
        "from langchain_together import ChatTogether\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.messages import BaseMessage\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# LangGraph components\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import AnyMessage, add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "# For pretty printing\n",
        "from rich.console import Console\n",
        "from rich.markdown import Markdown\n",
        "\n",
        "# --- API Key and Tracing Setup ---\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"03_TIDIT_Workshop\"\n",
        "\n",
        "# Check that the keys are set\n",
        "for key in [\"TOGETHER_API_KEY\", \"LANGSMITH_API_KEY\", \"TAVILY_API_KEY\"]:\n",
        "    if not os.environ.get(key):\n",
        "        print(f\"{key} not found. Please create a .env file and set it.\")\n",
        "\n",
        "print(\"Environment variables loaded and tracing is set up.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase1-title",
      "metadata": {},
      "source": [
        "## Phase 1: The Basic Approach - A Single-Shot Tool User\n",
        "\n",
        "To understand why ReAct is so powerful, we must first see what happens without it. We will build a \"basic\" agent that can use tools, but only once. It will analyze a user's query, make a single tool call, and then try to formulate a final answer based on that one piece of information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basic-what",
      "metadata": {},
      "source": [
        "### Step 1.1: Building the Basic Agent\n",
        "\n",
        "**What we are going to do:**\n",
        "We will define the same tool and LLM as before, but we will wire them into a simple, linear graph. The agent gets one chance to call a tool, and then the workflow ends. There is no loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "basic-build",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic single-shot tool-using agent compiled successfully.\n"
          ]
        }
      ],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "console = Console()\n",
        "\n",
        "# Define the state for our graphs\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "# Define the tool and LLM\n",
        "search_tool = TavilySearch(max_results=2, tavily_api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "llm = ChatTogether(\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "    temperature=0\n",
        ")\n",
        "llm_with_tools = llm.bind_tools([search_tool])\n",
        "\n",
        "# Define the agent node for the basic agent\n",
        "def basic_agent_node(state: AgentState):\n",
        "    console.print(\"--- BASIC AGENT: Thinking... ---\")\n",
        "    system_prompt = \"You are a helpful research assistant. You MUST use the web search tool to look up information relevant to the user's question.\"\n",
        "    messages = [(\"system\", system_prompt)] + state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def respond_node(state: AgentState):\n",
        "    \"\"\"Synthesizes a final answer from whatever the tool call returned.\"\"\"\n",
        "    console.print(\"--- BASIC AGENT: Responding... ---\")\n",
        "    system_prompt = \"You are a helpful assistant. Answer the user's question using ONLY the information available in the conversation so far. Do not ask for more information or suggest further searches.\"\n",
        "    messages = [(\"system\", system_prompt)] + state[\"messages\"]\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# The basic agent gets ONE tool call, then one synthesis step. No loop.\n",
        "# It will produce a coherent but incomplete answer, since it can only search once.\n",
        "basic_graph_builder = StateGraph(AgentState)\n",
        "basic_graph_builder.add_node(\"agent\", basic_agent_node)\n",
        "basic_graph_builder.add_node(\"tools\", ToolNode([search_tool]))\n",
        "basic_graph_builder.add_node(\"respond\", respond_node)\n",
        "\n",
        "basic_graph_builder.set_entry_point(\"agent\")\n",
        "basic_graph_builder.add_conditional_edges(\"agent\", tools_condition, {\"tools\": \"tools\", \"__end__\": \"__end__\"})\n",
        "basic_graph_builder.add_edge(\"tools\", \"respond\")\n",
        "basic_graph_builder.add_edge(\"respond\", END)\n",
        "\n",
        "basic_tool_agent_app = basic_graph_builder.compile()\n",
        "\n",
        "print(\"Basic single-shot tool-using agent compiled successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basic-test-what",
      "metadata": {},
      "source": [
        "### Step 1.2: Testing the Basic Agent on a Multi-Step Problem\n",
        "\n",
        "**What we are going to do:**\n",
        "Now we'll give the basic agent a problem that requires multiple, dependent steps to solve. This will expose its fundamental weakness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "basic-test-code",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Testing BASIC agent on a multi-step query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Who wrote the original novel that the 2021 film '</span>Dune' is based on? In \n",
              "what year did that author pass away? Which country won the FIFA World Cup in that same year?'\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;33mTesting BASIC agent on a multi-step query:\u001b[0m \u001b[32m'Who wrote the original novel that the 2021 film '\u001b[0mDune' is based on? In \n",
              "what year did that author pass away? Which country won the FIFA World Cup in that same year?'\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who wrote the original novel that the 2021 film 'Dune' is based on? In what year did that author pass away? Which country won the FIFA World Cup in that same year?\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- BASIC AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- BASIC AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_j2thqyd130x92532hqfqteqm)\n",
            " Call ID: call_j2thqyd130x92532hqfqteqm\n",
            "  Args:\n",
            "    query: author of Dune novel and year of death and FIFA World Cup winner\n",
            "    include_domains: None\n",
            "    exclude_domains: None\n",
            "    search_depth: advanced\n",
            "    include_images: False\n",
            "    time_range: None\n",
            "    topic: general\n",
            "    start_date: \n",
            "    end_date:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"author of Dune novel and year of death and FIFA World Cup winner\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Frank Herbert | Biography, Books, Dune, & Facts | Britannica FRANK HERBERT IS DEAD AT 65; AUTHOR OF THE 'DUNE' NOVELS Frank Herbert, Author of 'Dune' Series, Dies - Los Angeles Times Frank Herbert ‚Äì Dune Novels Frank Herbert | Dune Wiki | Fandom Frank Herbert | Biography, Books, Dune , & Facts | Britannica Frank Herbert - IMDb Frank Herbert - Wikipedia Frank Herbert | Biography, Books, Dune , & Facts | Britannica Frank Herbert - IMDb\", \"url\": \"https://www.britannica.com/biography/Frank-Herbert\", \"content\": \"Britannica Quiz\\n\\nFantasy Lands\\n\\nAn abortive film version of Dune was attempted in 1975 by Chilean-French director Alejandro Jodorowsky; that effort was chronicled in the documentary Jodorowsky‚Äôs Dune (2013). Dino De Laurentiis purchased the rights in 1976, and an adaptation was filmed by David Lynch (1984). A television miniseries aired in 2000, followed by another miniseries (2003), which covered the events in the second and third Dune books. In 2021 French Canadian director Denis Villeneuve released another film adaptation, which was based on the first half of Dune, and the sequel Dune: Part Two followed in 2024.\\n\\nQuick Facts\\n\\nIn full:\\n:   Frank Patrick Herbert\\n\\nBorn:\\n:   October 8, 1920, Tacoma, Washington, U.S.\\n\\nDied:\\n:   February 11, 1986, Madison, Wisconsin (aged 65) [...] Britannica Editors\\n\\nLast updated\\n\\n ‚Ä¢History\\n\\nFrank Herbert (born October 8, 1920, Tacoma, Washington, U.S.‚Äîdied February 11, 1986, Madison, Wisconsin) was an American science-fiction writer noted as the author of the best-selling Dune series of futuristic novels, a group of highly complex works that explore such themes as ecology, human evolution, the consequences of genetic manipulation, and mystical and psychic possibilities. [...] Died:\\n:   February 11, 1986, Madison, Wisconsin (aged 65)\\n\\nAwards And Honors:\\n:   Hugo Award (1966)\\n\\nNotable Works:\\n:   ‚ÄúChapterhouse: Dune‚Äù\\n:   ‚ÄúChildren of Dune‚Äù\\n:   ‚ÄúDragon in the Sea‚Äù\\n:   ‚ÄúDune Messiah‚Äù\\n:   ‚ÄúDune‚Äù\\n:   ‚ÄúGod Emperor of Dune‚Äù\\n:   ‚ÄúHeretics of Dune‚Äù\\n:   ‚ÄúThe Dosadi Experiment‚Äù\\n:   ‚ÄúThe God Makers‚Äù\\n:   ‚ÄúThe Heaven Makers‚Äù\\n:   ‚ÄúThe Santaroga Barrier‚Äù\\n\\nSee all related content\\n\\nIncluded among Herbert‚Äôs more than two dozen novels are the highly acclaimed Dragon in the Sea (1956), The Green Brain (1966), The Santaroga Barrier (1968), The Heaven Makers (1968), The God Makers (1972), and The Dosadi Experiment (1977).\\n\\nThe Editors of Encyclopaedia BritannicaThis article was most recently revised and updated by Encyclopaedia Britannica.\", \"score\": 0.7760977, \"raw_content\": null}, {\"url\": \"https://www.historylink.org/file/21248\", \"title\": \"Herbert, Frank Patrick (1920-1986) - HistoryLink.org\", \"content\": \"David Lynch: The Man From Another Plane (Boston-New York: Houghton Miflin Harcourt, 2015); Janet Maslin, \\\"Screen: Science Fiction Epic 'Dune',\\\" The New York Times, December 14, 1984, pg. C-18; Jon Michaud, \\\"Dune\\\" Endures,\\\" The New Yorker; July 12, 2013; \\\"Frank Herbert is Dead at 65: Author of the Dune Novels,\\\" The New York Times, February 13, 1986; Judy Quinn, \\\"Bantam Pays $3M for Dune 'Prequels' by Herbert's Son,\\\" Publisher's Weekly, November 17, 1997; Paul Stamets, Mycelium Running: How Mushrooms Can Help Save the World (Berkeley: Ten Speed Press, 2005); Damien Walters, \\\"Frank Herbert's Dune at 50 Has Life In It Yet,\\\" Guardian, January 30, 2015; State of California, County of Marin, Certificate of Death for Bruce Calvin Herbert, certified copy May 3, 2021.\", \"score\": 0.7316155, \"raw_content\": null}], \"response_time\": 3.69, \"request_id\": \"f488a9f7-aafd-45a1-ab41-97b9d7f038f6\"}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- BASIC AGENT: Responding<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- BASIC AGENT: Responding\u001b[33m...\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The original novel that the 2021 film 'Dune' is based on was written by Frank Herbert. He passed away on February 11, 1986. Argentina won the FIFA World Cup in 1986.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Final Output from Basic Agent</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "--- \u001b[1;31mFinal Output from Basic Agent\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The original novel that the 2021 film 'Dune' is based on was written by Frank Herbert. He passed away on February  \n",
              "11, 1986. Argentina won the FIFA World Cup in 1986.                                                                \n",
              "</pre>\n"
            ],
            "text/plain": [
              "The original novel that the 2021 film 'Dune' is based on was written by Frank Herbert. He passed away on February  \n",
              "11, 1986. Argentina won the FIFA World Cup in 1986.                                                                \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "multi_step_query = \"Who won the 2025 Booker Prize for Fiction? Who won the 2025 Nobel Prize in Literature? Are the two winners from the same country?\"\n",
        "\n",
        "console.print(f\"[bold yellow]Testing BASIC agent on a multi-step query:[/bold yellow] '{multi_step_query}'\\n\")\n",
        "\n",
        "basic_agent_output = None\n",
        "for chunk in basic_tool_agent_app.stream({\"messages\": [(\"user\", multi_step_query)]}, stream_mode=\"values\"):\n",
        "    basic_agent_output = chunk\n",
        "    chunk['messages'][-1].pretty_print()\n",
        "    console.print(\"\\n\")\n",
        "\n",
        "console.print(\"\\n--- [bold red]Final Output from Basic Agent[/bold red] ---\")\n",
        "console.print(Markdown(basic_agent_output['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "basic-discuss",
      "metadata": {},
      "source": [
        "**Discussion of the Output:**\n",
        "As expected, the basic agent's answer is incomplete. It made a single tool call ‚Äî likely a broad search for the entire complex query ‚Äî and then tried to synthesize an answer from that one result. Because it has no loop, it cannot follow up on gaps or refine its search. It was unable to properly break the problem down:\n",
        "1.  Find the company that made 'Dune' (Legendary Entertainment).\n",
        "2.  Find the CEO of that company (Joshua Grode).\n",
        "3.  Find that company's most recent film and its budget.\n",
        "\n",
        "This failure perfectly illustrates the need for a more dynamic approach. The agent needs a way to **react** to the information it finds in one step to inform the next."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase2-title",
      "metadata": {},
      "source": [
        "## Phase 2: The Advanced Approach - Implementing ReAct\n",
        "\n",
        "Now, we'll build the true ReAct agent. The core difference is the graph's structure: we will introduce a loop that allows the agent to repeatedly think, act, and observe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "react-build-what",
      "metadata": {},
      "source": [
        "### Step 2.1: Building the ReAct Agent Graph\n",
        "\n",
        "**What we are going to do:**\n",
        "We will define the nodes and the crucial router function that creates the `think -> act` loop. The key architectural change is the edge that routes the output from the `tool_node` *back* to the `agent_node`, allowing the agent to see the results and decide on its next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "react-build-code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ReAct agent compiled successfully with a reasoning loop.\n"
          ]
        }
      ],
      "source": [
        "REACT_SYSTEM_PROMPT = \"\"\"You are a research assistant that answers questions by searching for information step by step.\n",
        "\n",
        "Rules:\n",
        "- If you still need more information to fully answer the user's question, you MUST immediately call the tavily_search tool. Do NOT write out what you plan to search ‚Äî just call the tool directly.\n",
        "- Only search for ONE piece of information per tool call. Use short, focused queries.\n",
        "- If a search does NOT return the information you need, you MUST try again with a different, more specific query. Do not give up after a failed search.\n",
        "- When you have gathered ALL the information needed, write your final answer as plain text with no tool call. Every part of the user's question must be answered with a concrete fact ‚Äî never say \"not found\" or \"not specified\" without trying at least 2-3 different search queries first.\n",
        "\n",
        "Never say \"I will search for...\" or \"Next I need to look up...\" ‚Äî instead, just call the tool.\"\"\"\n",
        "\n",
        "def react_agent_node(state: AgentState):\n",
        "    console.print(\"--- REACT AGENT: Thinking... ---\")\n",
        "    messages = [(\"system\", REACT_SYSTEM_PROMPT)] + state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# The ToolNode is the same as before\n",
        "react_tool_node = ToolNode([search_tool])\n",
        "\n",
        "# The router is also the same logic\n",
        "def react_router(state: AgentState):\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if last_message.tool_calls:\n",
        "        console.print(\"--- ROUTER: Decision is to call a tool. ---\")\n",
        "        return \"tools\"\n",
        "    console.print(\"--- ROUTER: Decision is to finish. ---\")\n",
        "    return \"__end__\"\n",
        "\n",
        "# Now we define the graph with the crucial loop\n",
        "react_graph_builder = StateGraph(AgentState)\n",
        "react_graph_builder.add_node(\"agent\", react_agent_node)\n",
        "react_graph_builder.add_node(\"tools\", react_tool_node)\n",
        "\n",
        "react_graph_builder.set_entry_point(\"agent\")\n",
        "react_graph_builder.add_conditional_edges(\"agent\", react_router, {\"tools\": \"tools\", \"__end__\": \"__end__\"})\n",
        "\n",
        "# This is the key difference: the edge goes from tools BACK to the agent\n",
        "react_graph_builder.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "react_agent_app = react_graph_builder.compile()\n",
        "print(\"ReAct agent compiled successfully with a reasoning loop.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phase3-title",
      "metadata": {},
      "source": [
        "## Phase 3: Head-to-Head Comparison\n",
        "\n",
        "Now we will run the same complex query with our new ReAct agent and observe the difference in its process and final output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "react-test-what",
      "metadata": {},
      "source": [
        "### Step 3.1: Testing the ReAct Agent on the Multi-Step Problem\n",
        "\n",
        "**What we are going to do:**\n",
        "We will invoke the ReAct agent with the same multi-step query and stream the output to see its iterative reasoning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "react-test-code",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Testing ReAct agent on the same multi-step query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'Who wrote the original novel that the 2021 film '</span>Dune' is based \n",
              "on? In what year did that author pass away? Which country won the FIFA World Cup in that same year?'\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32mTesting ReAct agent on the same multi-step query:\u001b[0m \u001b[32m'Who wrote the original novel that the 2021 film '\u001b[0mDune' is based \n",
              "on? In what year did that author pass away? Which country won the FIFA World Cup in that same year?'\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who wrote the original novel that the 2021 film 'Dune' is based on? In what year did that author pass away? Which country won the FIFA World Cup in that same year?\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- REACT AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- REACT AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ROUTER: Decision is to call a tool. ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ROUTER: Decision is to call a tool. ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_vb6z0jcdbavbueo4gcr09s79)\n",
            " Call ID: call_vb6z0jcdbavbueo4gcr09s79\n",
            "  Args:\n",
            "    query: author of the novel Dune\n",
            "    include_images: False\n",
            "    search_depth: basic\n",
            "    topic: general\n",
            "    include_domains: ['']\n",
            "    exclude_domains: ['']\n",
            "    time_range: null\n",
            "    start_date: null\n",
            "    end_date: null\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "Error: 1 validation error for TavilySearchInput\n",
            "time_range\n",
            "  Input should be 'day', 'week', 'month' or 'year' [type=literal_error, input_value='null', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/literal_error\n",
            " Please fix your mistakes.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- REACT AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- REACT AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ROUTER: Decision is to call a tool. ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ROUTER: Decision is to call a tool. ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_jcky507c14stxqmkpi8n0xcs)\n",
            " Call ID: call_jcky507c14stxqmkpi8n0xcs\n",
            "  Args:\n",
            "    query: author of Dune novel\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"author of Dune novel\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.barnesandnoble.com/b/contributor/frank-herbert/_/N-2k97\", \"title\": \"List of Books by Frank Herbert\", \"content\": \"Dune author Frank Herbert wrote the original Dune novel and five sequels, making his contribution to the Dune series 6 books in total.\", \"score\": 0.87981987, \"raw_content\": null}, {\"url\": \"https://dunenovels.com/frank-herbert/\", \"title\": \"Frank Herbert\", \"content\": \"## Frank Herbert. **Frank Herbert author of the Dune Chronicles‚Äîthe Bestselling Science Fiction Adventure of All Time**. Frank Herbert (1920‚Äì1986) created the most beloved novel in the annals of science fiction, *Dune*. Having been divorced from his first wife, Flora Parkinson, Frank Herbert met Beverly Stuart at a University of Washington creative writing class in 1946. Frank had sold two pulp adventure stories to magazines, one to *Esquire* and the other to *Doc Savage*. For more than two decades Frank and Beverly would struggle to make ends meet, and there were many hard times. In all, Frank Herbert wrote nearly 30 popular books and collections of short stories, including six novels set in the Dune universe: *Dune, Dune Messiah, Children of Dune, God Emperor of Dune, Heretics of Dune*, and *Chapterhouse: Dune*. Frank Herbert‚Äôs last published novel, *Man of Two Worlds*, was a collaboration with his son, Brian. **For the complete biography of Frank Herbert, read *Dreamer of Dune* by Brian Herbert**.\", \"score\": 0.87605256, \"raw_content\": null}], \"response_time\": 0.85, \"request_id\": \"41db5efe-e6ec-44f2-bda6-7bbcfab07187\"}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- REACT AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- REACT AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ROUTER: Decision is to call a tool. ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ROUTER: Decision is to call a tool. ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_7rds0z4y4hs4nxnsnw5bokkz)\n",
            " Call ID: call_7rds0z4y4hs4nxnsnw5bokkz\n",
            "  Args:\n",
            "    query: year Frank Herbert died\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"year Frank Herbert died\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://strangehorizons.com/wordpress/non-fiction/reviews/tales-of-house-herbert-dreamer-of-dune-the-biography-of-frank-herbert/\", \"title\": \"Tales of House Herbert: Dreamer of Dune: The Biography of Frank ...\", \"content\": \"Frank Herbert died February 11, 1986, at a rather youthful 65 years of age, and at the height of his commercial success as a science fiction writer. Frank Herbert's path to becoming self-supporting as a professional author was both lengthy and tortured, running from his declaration on his eighth birthday that he wanted to be \\\"*a* author\\\" to the point in his fifty-first year when he was finally able to quit his outside job and write full-time. Frank Herbert's reaction to his considerable commercial success is equally fascinating -- consisting in no small part of a mad struggle to collect book advances quickly enough to cover his ever increasing spending -- and on this material Brian Herbert brings adult memories and perspective to his journal material. Wednesday: New Meat in a Clean Room edited by Ira Rat. Friday: The House of Illusionists and Other Stories by Vanessa Fogg. Monday: 2025 In Review: Part One. Wednesday: 2025 In Review: Part Two. Friday: 2025 In Review: Part Three.\", \"score\": 0.89720124, \"raw_content\": null}, {\"url\": \"https://www.imdb.com/name/nm0378541/\", \"title\": \"Frank Herbert(1920-1986) - IMDb\", \"content\": \"# Frank Herbert(1920-1986). Frank Herbert was born on 8 October 1920 in Tacoma, Washington, USA. He was a writer, known for Dune: Part One (2021), Dune (1984) and Dune: Part Two (2024). He died on 11 February 1986 in Madison, Wisconsin, USA. + and the novel 'Dune' by. + based on the novels by. * Jeu de r√¥le DUNE I #actualplay. + based on the novel Dune written by. * Frank Herbert's Cease Fire. Where Could Dune Go Next? Theresa Shackleford1985 - February 11, 1986 (his death). Won both the Nebula Award and the Hugo Award for his science fiction novel \\\"Dune\\\". Best known as the author of the science fiction novel \\\"Dune\\\". * When did Frank Herbert die? * How did Frank Herbert die? * How old was Frank Herbert when he died? * Where did Frank Herbert die? * When was Frank Herbert born? ### Recently viewed. You have no recently viewed pages.\", \"score\": 0.8898454, \"raw_content\": null}], \"response_time\": 1.64, \"request_id\": \"26a75acd-3d5e-45b2-b99a-ff18446627e6\"}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- REACT AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- REACT AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ROUTER: Decision is to call a tool. ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ROUTER: Decision is to call a tool. ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_2siq9pkq9v1lfrme9ai24l9j)\n",
            " Call ID: call_2siq9pkq9v1lfrme9ai24l9j\n",
            "  Args:\n",
            "    query: FIFA World Cup winner 1986\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"FIFA World Cup winner 1986\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/1986_FIFA_World_Cup\", \"title\": \"1986 FIFA World Cup - Wikipedia\", \"content\": \"| **AFC \\\"1986 FIFA World Cup qualification (AFC)\\\") (2)**   * Iraq (debut) * South Korea   **CAF \\\"1986 FIFA World Cup qualification (CAF)\\\") (2)**   * Algeria * Morocco   **OFC \\\"1986 FIFA World Cup qualification (OFC)\\\") (0)**   * *None qualified* | **CONCACAF \\\"1986 FIFA World Cup qualification (CONCACAF)\\\") (2)**   * Canada (debut) * Mexico¬†(hosts)   **CONMEBOL \\\"1986 FIFA World Cup qualification (CONMEBOL)\\\") (4)**   * Argentina * Brazil * Paraguay * Uruguay | **UEFA \\\"1986 FIFA World Cup qualification (UEFA)\\\") (14)**   * Belgium * Bulgaria * Denmark (debut) * England * France * Hungary * Italy¬†(defending champions) * Northern Ireland * Poland * Portugal * Scotland * Soviet Union * Spain * West Germany |  |. | * Mexico (hosts) * Italy (1982 winners) * West Germany (1982 runners-up) * Poland (1982 third place) * France (1982 fourth place) * Brazil (1982 fifth place) | * England * Soviet Union * Spain * Argentina * Paraguay * Uruguay | * Canada * Denmark * Algeria * Morocco * Iraq * South Korea | * Belgium * Bulgaria * Hungary * Northern Ireland * Portugal * Scotland |.\", \"score\": 0.8684817, \"raw_content\": null}, {\"url\": \"https://www.nytimes.com/athletic/6807126/2025/11/16/world-cup-winners-argentina-1986/\", \"title\": \"How Argentina won the 1986 World Cup: The relentless brilliance of ...\", \"content\": \"How Argentina won the 1986 World Cup: The relentless brilliance of Diego Maradona - The Athletic. Image 48: Composite image of photos from Argentina's 1986 World Cup finals campaign, including Diego Maradona lifting the trophy. How Argentina won the 1986 World Cup: The relentless brilliance of Diego Maradona. And then, with England still seething about the injustice of that 51st-minute opener, Maradona scored the best individual goal in World Cup history. Yes, he played more games than most, since Argentina reached the final, but Maradona went by three times as many players as anyone else. In a curious tournament that was widely regarded as a good World Cup despite the relative lack of outstanding sides, the caveats about Argentina‚Äôs success come from refereeing decisions in the quarter-final and semi-final: Maradona‚Äôs opener against England clearly shouldn‚Äôt have stood, and Belgium were twice wrongly flagged offside at 0-0 when through on goal three days later.\", \"score\": 0.8190992, \"raw_content\": null}], \"response_time\": 0.91, \"request_id\": \"f8f994e7-a6af-4c06-9a26-8722500bb9e8\"}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- REACT AGENT: Thinking<span style=\"color: #808000; text-decoration-color: #808000\">...</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- REACT AGENT: Thinking\u001b[33m...\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- ROUTER: Decision is to finish. ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- ROUTER: Decision is to finish. ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- <span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">Current State</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- \u001b[1;38;5;129mCurrent State\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The original novel that the 2021 film 'Dune' is based on was written by Frank Herbert. Frank Herbert passed away in 1986. The country that won the FIFA World Cup in 1986 was Argentina.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Final Output from ReAct Agent</span> ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "--- \u001b[1;32mFinal Output from ReAct Agent\u001b[0m ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The original novel that the 2021 film 'Dune' is based on was written by Frank Herbert. Frank Herbert passed away in\n",
              "1986. The country that won the FIFA World Cup in 1986 was Argentina.                                               \n",
              "</pre>\n"
            ],
            "text/plain": [
              "The original novel that the 2021 film 'Dune' is based on was written by Frank Herbert. Frank Herbert passed away in\n",
              "1986. The country that won the FIFA World Cup in 1986 was Argentina.                                               \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "console.print(f\"[bold green]Testing ReAct agent on the same multi-step query:[/bold green] '{multi_step_query}'\\n\")\n",
        "\n",
        "final_react_output = None\n",
        "for chunk in react_agent_app.stream({\"messages\": [(\"user\", multi_step_query)]}, stream_mode=\"values\"):\n",
        "    final_react_output = chunk\n",
        "    console.print(f\"--- [bold purple]Current State[/bold purple] ---\")\n",
        "    chunk['messages'][-1].pretty_print()\n",
        "    console.print(\"\\n\")\n",
        "\n",
        "console.print(\"\\n--- [bold green]Final Output from ReAct Agent[/bold green] ---\")\n",
        "console.print(Markdown(final_react_output['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "react-discuss",
      "metadata": {},
      "source": [
        "**Discussion of the Output:**\n",
        "Success! The execution trace shows a completely different and far more intelligent process. You can see the agent's step-by-step reasoning:\n",
        "1.  **Thought 1:** It first reasons that it needs to identify the production company for 'Dune'.\n",
        "2.  **Action 1:** It calls the `web_search` tool with a query like \"production company for Dune movie\".\n",
        "3.  **Observation 1:** It receives the result: \"Legendary Entertainment\".\n",
        "4.  **Thought 2:** Now, incorporating the new information, it reasons that it needs the CEO of Legendary Entertainment.\n",
        "5.  **Action 2:** It calls `web_search` again with a query like \"CEO of Legendary Entertainment\".\n",
        "6.  ...and so on, until it has gathered all the necessary pieces.\n",
        "7.  **Synthesis:** Finally, it assembles all the collected facts into a complete and accurate answer.\n",
        "\n",
        "This clearly demonstrates the superiority of the ReAct pattern for any task that isn't a simple, single-step lookup."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eval-what",
      "metadata": {},
      "source": [
        "## Phase 4: Quantitative Evaluation\n",
        "\n",
        "To formalize the comparison, we'll use an LLM-as-a-Judge to score the final outputs from both the basic and the ReAct agents on their ability to solve the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eval-judge-code",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- Evaluating Basic Agent's Output ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "--- Evaluating Basic Agent's Output ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'task_completion_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_quality_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'justification'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The agent successfully completed all parts of the user's request, providing the correct </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">information about the author of the novel 'Dune', the year of the author's death, and the country that won the FIFA</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">World Cup in that same year.\"</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'task_completion_score'\u001b[0m: \u001b[1;36m10\u001b[0m,\n",
              "    \u001b[32m'reasoning_quality_score'\u001b[0m: \u001b[1;36m10\u001b[0m,\n",
              "    \u001b[32m'justification'\u001b[0m: \u001b[32m\"The agent successfully completed all parts of the user's request, providing the correct \u001b[0m\n",
              "\u001b[32minformation about the author of the novel 'Dune', the year of the author's death, and the country that won the FIFA\u001b[0m\n",
              "\u001b[32mWorld Cup in that same year.\"\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- Evaluating ReAct Agent's Output ---\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "--- Evaluating ReAct Agent's Output ---\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'task_completion_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_quality_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'justification'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The agent successfully completed all parts of the user's request, providing accurate </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">information about the author of the original novel 'Dune', the year the author passed away, and the country that </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">won the FIFA World Cup in that same year. The agent's reasoning process was logical and demonstrated a good </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">understanding of the task.\"</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'task_completion_score'\u001b[0m: \u001b[1;36m10\u001b[0m,\n",
              "    \u001b[32m'reasoning_quality_score'\u001b[0m: \u001b[1;36m9\u001b[0m,\n",
              "    \u001b[32m'justification'\u001b[0m: \u001b[32m\"The agent successfully completed all parts of the user's request, providing accurate \u001b[0m\n",
              "\u001b[32minformation about the author of the original novel 'Dune', the year the author passed away, and the country that \u001b[0m\n",
              "\u001b[32mwon the FIFA World Cup in that same year. The agent's reasoning process was logical and demonstrated a good \u001b[0m\n",
              "\u001b[32munderstanding of the task.\"\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class TaskEvaluation(BaseModel):\n",
        "    \"\"\"Schema for evaluating an agent's ability to complete a task.\"\"\"\n",
        "    task_completion_score: int = Field(description=\"Score 1-10 on whether the agent successfully completed all parts of the user's request.\")\n",
        "    reasoning_quality_score: int = Field(description=\"Score 1-10 on the logical flow and reasoning process demonstrated by the agent.\")\n",
        "    justification: str = Field(description=\"A brief justification for the scores.\")\n",
        "\n",
        "judge_llm = llm.with_structured_output(TaskEvaluation)\n",
        "\n",
        "def evaluate_agent_output(query: str, agent_output: dict):\n",
        "    trace = \"\\n\".join([f\"{m.type}: {m.content}\" for m in agent_output['messages']])\n",
        "    prompt = f\"\"\"You are an expert judge of AI agents. Evaluate the following agent's performance on the given task on a scale of 1-10. A score of 10 means the task was completed perfectly. A score of 1 means complete failure.\n",
        "    \n",
        "    **User's Task:**\n",
        "    {query}\n",
        "    \n",
        "    **Full Agent Conversation Trace:**\n",
        "    ```\n",
        "    {trace}\n",
        "    ```\n",
        "    \"\"\"\n",
        "    return judge_llm.invoke(prompt)\n",
        "\n",
        "console.print(\"--- Evaluating Basic Agent's Output ---\")\n",
        "basic_agent_evaluation = evaluate_agent_output(multi_step_query, basic_agent_output)\n",
        "console.print(basic_agent_evaluation.model_dump())\n",
        "\n",
        "console.print(\"\\n--- Evaluating ReAct Agent's Output ---\")\n",
        "react_agent_evaluation = evaluate_agent_output(multi_step_query, final_react_output)\n",
        "console.print(react_agent_evaluation.model_dump())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eval-discuss",
      "metadata": {},
      "source": [
        "**Discussion of the Output:**\n",
        "The quantitative scores from the LLM-as-a-Judge make the difference crystal clear. \n",
        "- The **Basic Agent** received a very low `task_completion_score` because it failed to gather all the required information. Its `reasoning_quality_score` is also low because its process was flawed and incomplete.\n",
        "- The **ReAct Agent**, in contrast, received near-perfect scores. The judge recognized that its iterative process allowed it to successfully complete all parts of the complex task.\n",
        "\n",
        "This head-to-head comparison and evaluation provides definitive proof of the ReAct architecture's value. It is the key that unlocks an agent's ability to tackle complex, multi-hop problems that require dynamic adaptation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we have not only implemented the **ReAct** architecture but also demonstrated its clear superiority over a more basic, single-shot approach. By building a workflow that allows an agent to loop through a cycle of reasoning and acting, we have enabled it to solve complex, multi-step problems that would otherwise be intractable.\n",
        "\n",
        "The ability to observe the outcome of an action and use that information to inform the next step is a fundamental component of intelligent behavior. The ReAct pattern provides a simple yet profoundly effective way to build this capability into our AI agents, making them more powerful, adaptive, and useful for real-world tasks."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
